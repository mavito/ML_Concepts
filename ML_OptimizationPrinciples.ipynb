{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwFlf2GeoJKgp8de31OVHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavito/ML_Concepts/blob/main/ML_OptimizationPrinciples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizatoin Principles in Machine Learning**\n",
        "\n"
      ],
      "metadata": {
        "id": "obDZgy9ku4hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Unconstrained Optimization: Gradient Descent**\n",
        "\n",
        "The foundational algorithm for minimizing differentiable functions is Gradient Descent. It is an iterative method that starts at a random point in the parameter space and takes successive steps proportional to the negative of the gradient of the function at the current point.\n",
        "\n",
        "$$\\theta_{t+1} = \\theta_t - \\gamma \\nabla f(\\theta_t)$$\n",
        "\n",
        "Imagine an explorer who has been dropped by helicopter onto a vast, uneven mountain range at night.The explorer's goal is to reach the lowest point in the valley which is the bottom of the mountain to find a village (the optimal solution).\n",
        "However, there is a catch: a thick fog obscures the landscape.\n",
        "The explorer cannot see the village or even the terrain five feet ahead. They effectively have zero visibility of the global landscape. They cannot simply look at a map and walk to the lowest point. Instead, they must rely on local information.The explorer feels the ground beneath their feet. They can sense the slope. If the ground tilts upward to the right, they know that stepping to the left will take them lower. In this analogy:\n",
        "\n",
        "- The Mountain Terrain: Represents the Loss Function (Error Landscape). High peaks are high error; valleys are low error.\n",
        "- The Explorer's Position: Represents the model parameters $\\theta$ (weights and biases).\n",
        "- The Slope of the Ground: Represents the Gradient $\\nabla f$. It tells the explorer which direction is \"up.\"\n",
        "- The Step: The explorer takes a step in the direction opposite to the slope (downhill).\n",
        "- The Stride Length: Represents the Learning Rate $\\gamma$. A cautious explorer takes tiny steps; a reckless one takes giant leaps.\n",
        "\n",
        "By repeating this process—feeling the slope, turning downhill, and taking a step—thousands of times, the explorer eventually reaches a point where the ground is flat in all directions. They have reached a minimum."
      ],
      "metadata": {
        "id": "af-au5oIYMR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement basic gradient descent**\n",
        "\n",
        "We wiill now optimize a simple convex function where the global minimum is known, and verify the algorithm's success.\n",
        "\n",
        "Objective: Minimize the function $f(x) = x^2$.\n",
        "\n",
        "Derivative: $f'(x) = 2x$."
      ],
      "metadata": {
        "id": "ERx-ahxF0L0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qB-7Mxwz84j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define the Objective Function and its Gradient ---\n",
        "def func_quadratic(x):\n",
        "    \"\"\"\n",
        "    The objective function f(x) = x^2.\n",
        "    This represents the 'mountain' we are trying to descend.\n",
        "    \"\"\"\n",
        "    return x**2\n",
        "\n",
        "def grad_quadratic(x):\n",
        "    \"\"\"\n",
        "    The gradient (derivative) of the objective function.\n",
        "    For f(x) = x^2, f'(x) = 2x.\n",
        "    This tells us the slope of the mountain at any point x.\n",
        "    \"\"\"\n",
        "    return 2 * x\n",
        "\n",
        "# --- 2. The Gradient Descent Algorithm ---\n",
        "def gradient_descent_vanilla(start_x, learning_rate, num_iterations):\n",
        "    \"\"\"\n",
        "    Performs basic gradient descent.\n",
        "\n",
        "    Parameters:\n",
        "    start_x (float): The starting coordinate (initial guess).\n",
        "    learning_rate (float): The size of the step to take (gamma).\n",
        "    num_iterations (int): How many steps to take.\n",
        "\n",
        "    Returns:\n",
        "    history (list): A list of all x values visited during the descent.\n",
        "    \"\"\"\n",
        "    # Initialize position\n",
        "    x = start_x\n",
        "    history = [x]\n",
        "\n",
        "    # The Optimization Loop\n",
        "    for i in range(num_iterations):\n",
        "        # Calculate the slope (gradient) at current position\n",
        "        gradient = grad_quadratic(x)\n",
        "\n",
        "        # Update rule: Move opposite to the gradient\n",
        "        # x_new = x_old - learning_rate * gradient\n",
        "        x = x - learning_rate * gradient\n",
        "\n",
        "        # Log the new position\n",
        "        history.append(x)\n",
        "\n",
        "    return history\n",
        "\n",
        "# --- 3. Execution and Visualization ---\n",
        "# Configuration\n",
        "start_position = 10.0   # Start far away from the minimum (0)\n",
        "lr = 0.1                # Step size\n",
        "steps = 20              # Number of steps\n",
        "\n",
        "# Run Optimizer\n",
        "path = gradient_descent_vanilla(start_position, lr, steps)\n",
        "\n",
        "# Visualization\n",
        "x_axis = np.linspace(-12, 12, 100)\n",
        "y_axis = func_quadratic(x_axis)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_axis, y_axis, label='Objective Function $f(x)=x^2$')\n",
        "plt.scatter(path, [func_quadratic(p) for p in path], color='red', zorder=5, label='Gradient Descent Steps')\n",
        "plt.plot(path, [func_quadratic(p) for p in path], color='red', linestyle='--', alpha=0.5)\n",
        "plt.title(f'Gradient Descent Path (Learning Rate: {lr})')\n",
        "plt.xlabel('Parameter x')\n",
        "plt.ylabel('Cost f(x)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print final result\n",
        "print(f\"Starting Point: {start_position}\")\n",
        "print(f\"Final Position: {path[-1]:.5f}\")\n",
        "print(f\"Actual Minimum: 0.0\")"
      ],
      "metadata": {
        "id": "ioDDlc_Xzrg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1.1: Perform the following experiments to build intuition regarding hyperparameters:\n",
        "\n",
        "- Divergence Experiment:\n",
        "  - Change the learning_rate to 1.1.\n",
        "  - Run the code and observe the plot.\n",
        "  - The red dots should explode outwards, moving away from zero.\n",
        "  - This demonstrates \"overshooting\" caused by a step-size that is too large.\n",
        "  \n",
        "- Stagnation Experiment:\n",
        "  - Change the learning_rate to 0.0001.\n",
        "  - Increase steps to 20.\n",
        "  - Observe that the red dots barely move from the starting position.\n",
        "  - This demonstrates \"vanishing updates\" or slow convergence caused by a step-size that is too small.\n",
        "\n",
        "- Non-Convex Challenge:\n",
        "  - Change the objective function to f(x) = x**4 - 2*x**2 (a W-shaped curve).\n",
        "  - Its derivative is 4*x**3 - 4*x.\n",
        "  - Start the optimizer at x = 0.\n",
        "  - Observe that the gradient is 0, so the optimizer does not move, even though $x=0$ is a local maximum (a hill), not a minimum.\n",
        "  - This illustrates the danger of saddle points and local extrema."
      ],
      "metadata": {
        "id": "6GSVaqVp0PWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE CODE HERE"
      ],
      "metadata": {
        "id": "73VedPQskVWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Learning Rate**\n",
        "\n",
        "Returning to the mountain analogy, the step-size is the length of the explorer's stride.\n",
        "\n",
        "- **Tiny Stride:**\n",
        "  - If the explorer takes steps measuring only a few millimeters, they will descend safely.\n",
        "  - They will never accidentally walk up the other side of the valley.\n",
        "  - However, if the valley is 10 miles deep, they will die of old age before reaching the bottom.\n",
        "  - This corresponds to a computationally expensive training process that might never finish.\n",
        "\n",
        "- **Giant Leap:**\n",
        "  - If the explorer can jump 1 mile at a time, they might jump from one side of the valley to the other, completely missing the village at the bottom.\n",
        "  - If the jump is too strong, they might even land higher up on the opposite slope, gaining altitude (increasing loss) with every jump.\n",
        "  - This corresponds to the model parameters diverging, often resulting in NaN (Not a Number) errors in the code."
      ],
      "metadata": {
        "id": "sN_8X1Sj0Qe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Momentum**\n",
        "\n",
        "Standard Gradient Descent behaves like a massless particle; it has no inertia. If the gradient changes direction, the particle changes direction instantly. Momentum transforms the explorer into a \"Heavy Ball\" rolling down the mountain.   \n",
        "\n",
        "When a heavy ball rolls down a ravine:\n",
        "\n",
        "- Dampening Oscillations: As it bounces between the left and right walls, the momentum vectors in the \"left\" direction and \"right\" direction effectively cancel each other out over time. The ball doesn't instantaneously reverse; it turns slowly.\n",
        "\n",
        "- Accumulating Speed: As the ball rolls down the gentle slope of the valley floor, the acceleration (gradient) is consistently in the same direction. The velocity vector accumulates these small pushes, causing the ball to roll faster and faster.\n",
        "\n",
        "This allows the heavy ball to barrel down the valley floor much faster than the careful explorer who stops to check the map at every meter.   "
      ],
      "metadata": {
        "id": "YMqmHJpQ69zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement Momentum on a 2D \"ravine\" function to visualize the difference in trajectory compared to vanilla Gradient Descent.\n",
        "\n",
        "Objective: Minimize the 2D function $f(x, y) = x^2 + 10y^2$.\n",
        "\n",
        "Gradients: $\\frac{\\partial f}{\\partial x} = 2x$, $\\frac{\\partial f}{\\partial y} = 20y$.\n",
        "\n",
        "Note: The surface is 10 times steeper in the y-direction, creating a ravine aligned with the x-axis."
      ],
      "metadata": {
        "id": "hp6tdKMe8uVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Ravine Function ---\n",
        "def func_ravine(theta):\n",
        "    x, y = theta, theta\n",
        "    return x**2 + 10 * y**2\n",
        "\n",
        "def grad_ravine(theta):\n",
        "    x, y = theta, theta\n",
        "    return np.array([2*x, 20*y])\n",
        "\n",
        "# --- 2. Momentum Optimizer ---\n",
        "def gradient_descent_momentum(start_theta, lr, momentum, iterations):\n",
        "    \"\"\"\n",
        "    Performs Gradient Descent with Momentum.\n",
        "\n",
        "    Parameters:\n",
        "    start_theta (array): Starting [x, y] coordinates.\n",
        "    lr (float): Learning rate.\n",
        "    momentum (float): Momentum coefficient (mu), typically 0.9.\n",
        "    iterations (int): Number of steps.\n",
        "    \"\"\"\n",
        "    theta = np.array(start_theta)\n",
        "    velocity = np.zeros_like(theta) # Velocity starts at 0\n",
        "    history = [theta.copy()]\n",
        "\n",
        "    for i in range(iterations):\n",
        "        grad = grad_ravine(theta)\n",
        "\n",
        "        # Update Velocity\n",
        "        # v_new = mu * v_old - learning_rate * gradient\n",
        "        velocity = momentum * velocity - lr * grad\n",
        "\n",
        "        # Update Position\n",
        "        theta = theta + velocity\n",
        "\n",
        "        history.append(theta.copy())\n",
        "\n",
        "    return np.array(history)\n",
        "\n",
        "# --- 3. Execution ---\n",
        "start_pos = [10.0, 10.0]\n",
        "lr = 0.05\n",
        "mu = 0.9\n",
        "steps = 50\n",
        "\n",
        "# Run Momentum\n",
        "path_momentum = gradient_descent_momentum(start_pos, lr, mu, steps)\n",
        "\n",
        "# Run Vanilla for comparison (using helper from previous section adapted for 2D)\n",
        "# Note: Students would re-use their previous function or write a 2D wrapper\n",
        "#... (Vanilla GD implementation omitted for brevity, assumed available)...\n",
        "\n",
        "# --- 4. Visualization (Contour Plot) ---\n",
        "x_grid = np.linspace(-12, 12, 100)\n",
        "y_grid = np.linspace(-12, 12, 100)\n",
        "X, Y = np.meshgrid(x_grid, y_grid)\n",
        "Z = X**2 + 10*Y**2\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.contour(X, Y, Z, levels=20, cmap='viridis')\n",
        "plt.plot(path_momentum[:,0], path_momentum[:,1], 'r-o', label='Momentum')\n",
        "# plt.plot(path_vanilla[:,0], path_vanilla[:,1], 'b-x', label='Vanilla GD') # Theoretical comparison line\n",
        "plt.title(f'Momentum vs Vanilla GD in a Ravine (lr={lr}, mu={mu})')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wdmEXJVbk4IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3.1 :\n",
        "\n",
        "**Comparative Analysis:** Implement a standard 2D Gradient Descent (without momentum). Run both algorithms on the function $f(x, y) = x^2 + 10y^2$ starting at $(10, 10)$ with a learning rate of $0.05$.\n",
        "\n",
        "**Observation:** Plot the paths. The standard GD should zig-zag heavily across the Y-axis. The Momentum path should initially swing wide but then curve smoothly towards the center $(0,0)$ and accelerate along the X-axis.\n",
        "\n",
        "**Tuning:** Try setting momentum = 0.1. Does it behave more like the heavy ball or more like standard GD? (Answer: Low momentum makes it behave like standard GD)."
      ],
      "metadata": {
        "id": "OYbMNCOv89YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE CODE HERE"
      ],
      "metadata": {
        "id": "GK5_VhXx9vak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Scalable Optimization: Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "In modern machine learning, datasets are enormous. Calculating the exact gradient involves summing the error over every single data point.$$\\nabla L(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla L_i(\\theta)$$\n",
        "If $N = 1,000,000$, a single step of Gradient Descent requires one million calculations. This is known as Batch Gradient Descent, and it is computationally prohibitive for large data.\n",
        "\n",
        "**Stochastic Gradient Descent (SGD)** approximates the true gradient by calculating the gradient using only one single random data point (or a small batch) at each step.$$\\theta_{t+1} = \\theta_t - \\gamma \\nabla L_i(\\theta_t)$$\n",
        "Where $(x_i, y_i)$ is a random training example chosen at step $t$."
      ],
      "metadata": {
        "id": "IDrGBHgD97rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine a politician wants to know the public opinion (the true gradient) to adjust their campaign strategy (the parameters).\n",
        "\n",
        "- Batch Gradient Descent: The politician conducts a full national census, asking every citizen their opinion before making a single decision. This is accurate but takes years. By the time the decision is made, the election is over.\n",
        "\n",
        "- Stochastic Gradient Descent: The politician asks one random person on the street and adjusts their strategy based on that single opinion. This is noisy (that person might be an outlier), but it is instant. The politician can make millions of small adjustments in the time it takes to do one census. Over time, the \"random walk\" of adjustments averages out to the correct strategy."
      ],
      "metadata": {
        "id": "UPoLS7av90pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Updated for modern machines : Mini-Batch Gradient Descent**\n",
        "\n",
        "In practice, we rarely use a batch size of 1. We use a Mini-Batch (e.g., 32, 64, or 128 samples). This offers a \"best of both worlds\" solution:\n",
        "\n",
        "- Stability: The average gradient of 32 points is much less noisy than 1 point.\n",
        "\n",
        "- Speed: Computing 32 gradients is much faster than 1 million.\n",
        "\n",
        "- Hardware Efficiency: Modern GPUs are designed to process matrices (batches) of data in parallel, making a batch of 32 almost as fast to compute as a batch of 1.   "
      ],
      "metadata": {
        "id": "LyOYulzo-YT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will implement SGD to solve a Linear Regression problem on synthetic data.\n",
        "#This introduces the concept of \"Epochs\" (one full pass through the data) versus \"Iterations\" (one update step).\n",
        "\n",
        "#Objective: Fit a line y = mx + c to noisy data.\n",
        "# --- 1. Data Generation ---\n",
        "def generate_data(n_samples=100):\n",
        "    np.random.seed(42)\n",
        "    X = 2 * np.random.rand(n_samples, 1)\n",
        "    # True relationship: y = 4 + 3x + noise\n",
        "    y = 4 + 3 * X + np.random.randn(n_samples, 1)\n",
        "    return X, y\n",
        "\n",
        "# --- 2. SGD Implementation ---\n",
        "def stochastic_gradient_descent(X, y, learning_rate=0.1, n_epochs=50):\n",
        "    m = len(X)\n",
        "    # Add bias term (x0 = 1) to X for matrix math\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "\n",
        "    # Initialize parameters randomly (theta=intercept, theta=slope)\n",
        "    theta = np.random.randn(2, 1)\n",
        "    path = [theta.copy()]\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for i in range(m):\n",
        "            # Pick ONE random instance\n",
        "            random_index = np.random.randint(m)\n",
        "            xi = X_b[random_index:random_index+1]\n",
        "            yi = y[random_index:random_index+1]\n",
        "\n",
        "            # Compute gradient for this ONE instance\n",
        "            # Prediction: xi * theta\n",
        "            # Error: prediction - yi\n",
        "            # Gradient: 2 * xi.T * error\n",
        "            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
        "\n",
        "            # Update parameters\n",
        "            theta = theta - learning_rate * gradients\n",
        "            path.append(theta.copy())\n",
        "\n",
        "    return theta, np.array(path)\n",
        "\n",
        "# --- 3. Execution ---\n",
        "X_data, y_data = generate_data(100)\n",
        "final_theta, theta_path = stochastic_gradient_descent(X_data, y_data, learning_rate=0.1, n_epochs=50)\n",
        "\n",
        "print(f\"True Params: Intercept=4, Slope=3\")\n",
        "print(f\"Learned Params: Intercept={final_theta}, Slope={final_theta}\")\n",
        "\n",
        "# --- 4. Visualization ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(theta_path[:, 0], theta_path[:, 1], \"r-\", linewidth=0.5, label=\"SGD Path\")\n",
        "plt.plot(4, 3, \"bo\", markersize=10, label=\"True Minimum\")\n",
        "plt.xlabel(r\"$\\theta_0$ (Intercept)\")\n",
        "plt.ylabel(r\"$\\theta_1$ (Slope)\")\n",
        "plt.title(\"SGD Path in Parameter Space\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "karK3Y73-gO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.1 : Observe\n",
        "\n",
        "1. Noise Observation: Run the code and examine the plot. The red line should be extremely \"jittery\" or squiggly. Unlike the smooth curve of Gradient Descent, SGD wanders around.\n",
        "\n",
        "2. Mini-Batch Implementation: Modify the code to sample batch_size=10 indices instead of 1. Calculate the mean gradient of these 10 points.\n",
        "\n",
        "3. Comparison: Plot the path of SGD (Batch=1) vs Mini-Batch (Batch=10). The Mini-Batch path should be smoother and more direct, confirming the variance reduction theory.   "
      ],
      "metadata": {
        "id": "msv-497s-s5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Constrained Optimization: Lagrange Multipliers**\n",
        "\n",
        "This deals with problems where we must minimize a function $f(x)$ subject to certain conditions, such as $g(x) = 0$ (equality constraint) or $h(x) \\le 0$ (inequality constraint).\n",
        "\n",
        "Typical examples in machine learning include:\n",
        "- Support Vector Machines (SVM): Minimize the norm of weights subject to correct classification constraints.\n",
        "- Principal Component Analysis (PCA): Maximize variance subject to the basis vectors being orthogonal and unit length.\n",
        "\n",
        "The method of Lagrange Multipliers transforms a constrained problem into an unconstrained one by introducing a new variable, $\\lambda$ (lambda), called the Lagrange Multiplier.\n",
        "\n",
        "Imagine you are hiking on a mountain. The mountain is the objective function $f(x)$ (where height = value). You want to find the highest point you can reach. However, there is a strict rule: you must stay on a specific hiking trail. The trail is the constraint $g(x)=0$.\n",
        "\n",
        "You cannot simply walk to the summit if the trail doesn't go there. You must find the highest point on the trail.\n",
        "\n",
        "- If the trail cuts across the contour lines of the mountain (i.e., you are walking steeply uphill or downhill), you are clearly not at the peak. You can keep walking along the trail to go higher.\n",
        "- You reach the highest point on the trail when the trail runs tangent to the contour line of the mountain. At this specific point, the direction of steepest ascent (the gradient of the mountain) is perpendicular to the trail. Since the gradient of the constraint (the direction perpendicular to the trail) is also perpendicular to the trail, the two gradients are parallel (aligned).\n",
        "\n",
        "The Lagrange Multiplier $\\lambda$ simply scales the two gradients so they cancel each other out."
      ],
      "metadata": {
        "id": "wKKW0QLU_JMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solving Constrained Problems**\n",
        "\n",
        "Constrained optimization is numerically difficult to implement from scratch because \"staying on the trail\" ($g(x)=0$) exactly is hard for discrete iterative steps. Therefore, we will use the robust scipy.optimize library, which implements sophisticated algorithms like SLSQP (Sequential Least SQuares Programming).\n",
        "\n",
        "Objective: Maximize the area of a rectangle $A = x \\cdot y$ subject to the constraint that its perimeter is fixed at 20 ($2x + 2y = 20$).\n",
        "\n",
        "*Note: We know the answer is a square ($5 \\times 5$), but we will solve it numerically.*"
      ],
      "metadata": {
        "id": "vvrAqN_ZWvlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# --- 1. Define Problem ---\n",
        "def objective_func(x):\n",
        "    # We want to MAXIMIZE Area = x*y\n",
        "    # Scipy minimizes, so we minimize -Area\n",
        "    return -(x * x)\n",
        "\n",
        "def constraint_func(x):\n",
        "    # Constraint: 2x + 2y = 20\n",
        "    # Standard form: g(x) = 0 -> 2x + 2y - 20 = 0\n",
        "    return 2 * x + 2 * x - 20\n",
        "\n",
        "# --- 2. Setup Optimization ---\n",
        "# Initial guess (start with a skinny rectangle)\n",
        "x0 =\n",
        "\n",
        "# Define constraint dictionary for Scipy\n",
        "# 'eq' means Equality Constraint (g(x) = 0)\n",
        "cons = ({'type': 'eq', 'fun': constraint_func})\n",
        "\n",
        "# --- 3. Execute Optimization ---\n",
        "# We use SLSQP method which handles constraints\n",
        "solution = minimize(objective_func, x0, method='SLSQP', constraints=cons)\n",
        "\n",
        "# --- 4. Results ---\n",
        "print(f\"Optimization Status: {solution.message}\")\n",
        "print(f\"Optimal Dimensions: x={solution.x:.2f}, y={solution.x:.2f}\")\n",
        "print(f\"Max Area: {-solution.fun:.2f}\")\n",
        "\n",
        "# --- 5. Visualization (Geometric Intuition) ---\n",
        "x_range = np.linspace(0, 10, 100)\n",
        "y_range = np.linspace(0, 10, 100)\n",
        "X, Y = np.meshgrid(x_range, y_range)\n",
        "Z = X * Y # The Objective Surface (Area)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "# Plot Contour lines of Area\n",
        "CS = plt.contour(X, Y, Z, levels=20, cmap='viridis')\n",
        "plt.clabel(CS, inline=1, fontsize=10)\n",
        "\n",
        "# Plot the Constraint Line (2x + 2y = 20 -> y = 10 - x)\n",
        "y_constraint = 10 - x_range\n",
        "plt.plot(x_range, y_constraint, 'r-', linewidth=2, label='Constraint: Perimeter=20')\n",
        "\n",
        "# Plot the Solution\n",
        "plt.plot(solution.x, solution.x, 'k*', markersize=15, label='Optimal Point')\n",
        "\n",
        "plt.xlim(0, 10)\n",
        "plt.ylim(0, 10)\n",
        "plt.title(\"Geometric Interpretation of Lagrange Multipliers\")\n",
        "plt.xlabel(\"Width x\")\n",
        "plt.ylabel(\"Height y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7pAcTR7K_f-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5.1:\n",
        "\n",
        "- Constraint Modification: Change the constraint to a circle: $x^2 + y^2 = 20$. Update the constraint_func and the visualization code.\n",
        "\n",
        "- Prediction: Before running, predict the shape of the solution. (Answer: A square is still the optimal rectangle inscribed in a circle).\n",
        "- Verification: Run the code. Does the red line (now a red circle) touch the contour curves tangentially? This reinforces the universality of the geometric interpretation."
      ],
      "metadata": {
        "id": "InOZKkvO_qdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE CODE HERE"
      ],
      "metadata": {
        "id": "f8LUCDMbAIg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Convex Optimization**\n",
        "\n",
        "**6.1 Convex Sets and Functions**\n",
        "\n",
        "**Convex Set:** A shape is convex if, for any two points inside the shape, the straight line connecting them is also entirely inside the shape.\n",
        "- Examples: A circle, a square, a cube.\n",
        "- Counter-examples: A crescent moon, a donut (the line crosses the hole).\n",
        "\n",
        "**Convex Function:** A function is convex if a line segment connecting any two points on its graph lies above or on the graph.\n",
        "\n",
        "- Visual: A bowl ($x^2$).\n",
        "- Mathematical: $f(\\alpha x + (1-\\alpha)y) \\le \\alpha f(x) + (1-\\alpha)f(y)$ for $\\alpha \\in $.\n",
        "\n",
        "**The Fundamental Theorem:**\n",
        "\n",
        "For a convex function defined on a convex set, any local minimum is also the global minimum.This property is profoundly important.\n",
        "\n",
        "It means that if you are optimizing a convex problem (like Logistic Regression or SVMs) and your gradient becomes zero, you can stop immediately. You have found the absolute best solution. You do not need to worry about being stuck in a sub-optimal valley, because there are no sub-optimal valleys; there is only one global valley floor.\n",
        "\n",
        "**6.2 Linear and Quadratic Programming**\n",
        "\n",
        "Two major subclasses of convex optimization are vital in operations research and machine learning:\n",
        "1. Linear Programming (LP): The objective function is linear, and the constraints are linear inequalities. The feasible region is a convex polygon. The solution always lies at one of the vertices (corners) of the polygon.\n",
        "\n",
        "2. Quadratic Programming (QP): The objective function is quadratic (convex), and the constraints are linear. This is the exact form of the Support Vector Machine (SVM) optimization problem. The SVM objective (minimize $\\|w\\|^2$) is a convex bowl, and the constraints (classify data points correctly) form linear fences cutting through that bowl."
      ],
      "metadata": {
        "id": "OlD6zRAsAJko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visually distinguish between convex and non-convex functions to understand why convexity is desirable.\n",
        "\n",
        "def plot_convexity():\n",
        "    x = np.linspace(-2, 2, 100)\n",
        "\n",
        "    # Convex Function: f(x) = x^2\n",
        "    y_convex = x**2\n",
        "\n",
        "    # Non-Convex Function: g(x) = x^4 - x^2 + 0.1*x\n",
        "    # (A wavy function with two dips)\n",
        "    y_nonconvex = x**4 - x**2 + 0.1*x\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot 1: Convex\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, y_convex, 'b-')\n",
        "    plt.title(\"Convex Function ($x^2$)\")\n",
        "    # Draw a chord to prove convexity\n",
        "    plt.plot([-1, 1],[1,1] , 'r--', label='Chord lies ABOVE function')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 2: Non-Convex\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, y_nonconvex, 'g-')\n",
        "    plt.title(\"Non-Convex Function ($x^4 - x^2 + 0.1x$)\")\n",
        "    # Draw a chord to prove non-convexity\n",
        "    plt.plot([-1, 1], [(-1)**4 - (-1)**2 - 0.1, 1**4 - 1**2 + 0.1], 'r--', label='Chord crosses function')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_convexity()"
      ],
      "metadata": {
        "id": "rypxr_SXrWQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6.1:\n",
        "\n",
        "- Visual Identification: Run the code. Notice how the red dashed line (the chord) sits comfortably inside the \"bowl\" of the convex function.\n",
        "\n",
        "- Chord Violation: Notice how on the right, the red line cuts through the \"hill\" in the middle of the W-shape. This crossing proves the function is non-convex.\n",
        "\n",
        "- Optimization Consequence: Mentally initialize a ball at $x=0$ on both graphs.On the left (convex), the ball rolls to the only minimum.On the right (non-convex), the ball at $x=0$ is balanced on a local maximum.\n",
        "  - If pushed slightly left, it falls into one valley.\n",
        "  - If pushed right, it falls into a different valley.\n",
        "\n",
        "This illustrates the initialization sensitivity of non-convex problems (like Neural Networks)."
      ],
      "metadata": {
        "id": "FlsKwzRIBC9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE CODE HERE"
      ],
      "metadata": {
        "id": "EPwZ5vpYBFDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}